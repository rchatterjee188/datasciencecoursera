---
title: "Code_Lib_Manipulate"
author: "Ruhika Chatterjee"
date: "2024-12-07"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Notes taken from Johns Hopkins University Coursera course series Data Science Specialization.

# R Data Types
- Basic object is vector of same class except list.  
- Atomic classes of objects: character, numeric (real), integer, complex, logical.  
- Attributes can include names, dimnames, dimensions, class, length.

### Atomic Data
``` {r atomicClass}

# numeric Vector
x <- 5 # numeric vector of 1 element

# integer vector
x <- 5L # integer vector of len 1

x <- Inf # special number infinity, +/-
x <- NaN # special number undefined, usually hijacks operations

# character vector
msg <- "hello" # char vector of len 1

# logical vector
tf <- TRUE # logical vector of value true
# TRUE = 1 = T, FALSE = 0 = F, num > 0 = TRUE

# complex vector
x <- 1+4i # vector of complex num of len 1

```

### complex Data Types
``` {r complexData}
# vector
vector("numeric", length = 10) # create vector of one type, args: class, length
c(1,2,3,4) # creates vector of common denominator class with given values
1:20 # vector sequence of 20 elements 1-20
pi:10 # will not exceed 10, start from pi, increment by 1
15:1 # increment -1
seq(1,20) # same as :
seq(0,10,by=0.5) # to change increment
seq(5,10,length=30) # to not set increment but number of numbers
seq_along(c(1,3,8,25,100)) # vector of same length 1:length(x) or seq(along=c(1,3,8,25,100))
rep(10, times = 4) # repeats 10 4 times in vector
rep(c(0, 1, 2), times = 10) # repeats sequence of vector 10 times. Arg each can be used to repeat first, then second... element in vector.

# lists
# vector capable of carrying different classes
x <- list(1, "a", TRUE, 1+4i) # vector of vectors

# Matrix
# vector of single class with rectangular dimensions (attribute of integer vector len 2)
x <- matrix(nrow=2,ncol=3) # empty matrix of given dimensions
x <- matrix(1:8, nrow = 4, ncol = 2) # creates matrix of given dimensions with values assigned, created by column
y <- matrix(rep(10,4),2,2) # creates matrix of 4 10s

x <- 1:10
dim(x) <- c(2,5) # creates matrix out of vector with dimension 2 rows x 5 columns

cbind(1:3,10:12) # creates matrix out of values in vector args, adding by column (1st arg = 1st col)
rbind(1:3,10:12) # same but using rows

# factors
# self-describing type of vector representing categorical data, ordered or unordered (labels)
x <- factor(c("male","female","female","female","male")) # character vector with specific linear modeling capabilities, levels also in output. Must set levels if want to order, auto alphabetical.
f <- gl(3,10) # factor 3 levels, 10 times each
yesno <- factor(sample(c("yes","no"), size = 10, replace = TRUE)) # randomly generate factor vector
relevel(yesno, ref = "yes") # change oder of levels
table(x) # prints counts of each factor


# Data Frames
# stores tabular/rectangular data, stored as lists of same length where each element is a column, length of element is number of rows. Different classes possible
x <- data.frame(foo=1:4, bar=c(T,T,F,F)) # creates data frame 2 columns foo and bar, 4 rows unnamed. Can also combine with matrices

```

### Data Tables (not Frames)
- Package, faster and more memory efficient  
- Inherets from data.frame (all functions), written in C, faster at sub-setting, grouping, and updating  
- Much faster reading time and different operations
- <http://stackoverflow.com/questions/13618488/what-you-can-do-with-data-frame-that-you-cant-in-data-table>  
- <https://github.com/Rdatatable/data.table>  

``` {r dataTable}
library(data.table)
DF = data.frame(x=rnorm(9),y=rep(c("a","b","c"), each=3),z=rnorm(9))
head(DF,3)

DT = data.table(x=rnorm(9),y=rep(c("a","b","c"), each=3),z=rnorm(9))
head(DT,3)
tables() # get all data tables in memory

# subsetting
DT[2,] # subset rows
DT[DT$y=="a",] # subset where y is "a"
DT[c(2,3)] # subset rows 2 & 3, one variable is assigned to rows
# subset cols, DT[,c(2.3)] does not work bc uses expressions
DT[,list(mean(x),sum(z))] # pass list of functions applied by names of columns
DT[,table(y)] # get table of y values
DT[, w := z^2] # adds columns quickly
DT2 <- DT # does not make a copy in memory, change one changes all, pointing to same memory. Use copy function
DT[,m:= {tmp <- (x+z); log2(tmp+5)}] # multiple step function, returns last statement in evaluation
DT[,a:=x>0] # expression exaluates boolean for new variable
DT[,b:= mean(x+w),by=a] # grouping by boolean a into factors to evaluate expression
# special variable .N integer len 1 num times group appears
set.seed(123)
DT <- data.table(x=sample(letters[1:3], 1E5, TRUE))
DT[, .N, by=x] # count number of times grouped by x variable

# data.table contains keys
DT <- data.table(x=rep(c("a","b","c"),each=100), y=rnorm(300))
setkey(DT, x)
DT["a"] # subset based on key x, faster
DT1 <- data.table(x=c("a","a","b","dt1"), y=1:4)
DT2 <- data.table(x=c("a","b","dt2"), z=5:7)
setkey(DT1,x); setkey(DT2,x)
merge(DT1,DT2) # uses keys to merge

# fast reading in data.table
big_df <- data.frame(x=rnorm(1E5),y=rnorm(1E5))
file <- tempfile()
write.table(big_df, file=file, row.names=FALSE, col.names=TRUE, sep="\t", quote=FALSE)
system.time(fread(file)) # basically read.table for csv
system.time(read.table(file,header=TRUE,sep="\t"))

```

### Date and Time Data Types
``` {r datetime}
# useful for time-series data (temporal changes) or other temporal info
# lubridate package by Hadley Wickham

# Dates and Times
birthday <- as.Date("1970-01-01") # dates are date class defined by converting character string, year-month-day, stored as number of days since 1970-01-01 (previous is negative)
today <- Sys.Date()

currentTime <- Sys.time()# time by POSIXct(large integer vector, useful in dataframe) or POSIXlt(list, other info stored like day) class, stored internally as number of seconds since 1970-01-01 or list, respectively
timedefined <- as.POSIXct("2012-10-25 06:00:00") # convert char vector, can define timezone
cTConvert <- as.POSIXlt(currentTime) # reclass, works other way
cTConvert$min # to subset list

datestring <- c("January 10, 2012 10:40", "December 9, 2011 9:10")
x <- strptime(datestring, "%B %d, %Y %H:%M") # Convert character vector to POSIXlt by defining format (format string)
x

weekdays(birthday) # return day of week, date or time classes
months(birthday) # return month on date or time
quarters(birthday) # return quarter of date or time

# Operations
# CANNOT MIX CLASSES - convert
# add and subtract dates, compare dates
currentTime - timedefined # time difference, track of discrepancies (i.e. daylightsavings, timezones, leap time, etc). Can do + and - or <, >, <=, >=, ==, !=.
difftime(currentTime, timedefined, units = "days") # to specify unit

rm(list=ls())

```


# Basic R Functions

### Functions and Operations
Mathematical functions: <http://www.biostat.jhsph.edu/~ajaffe/lec_winterR/Lecture%202.pdf>  <http://statmethods.net/management/functions.html>
``` {r basic}
# Input and Evaluation
x <- 1 # assignment operator, evaluates and returns
print(x) # print value as vector
x # auto-prints
# in console, press Tab for auto-completion
LETTERS # predefined character vector of capital letters
# <<- operator can be used to assign a value to an object in an environment that is different from the current environment

# Mathematical and Statistical Functions
5 + 7 # basic arithmetic operations all work +, -, *, /, ^, %% (modulus). NA affects operation.
sqrt(4) # square root
abs(-1:2) # absolute value
ceiling(3.275) # round ceiling
floor(3.275) # round floor
round(3.275, digits = 1) # round to the num def digits after decimal
signif(3.275, digits = 2) # digits number of sig figs
mean(c(3,4,5,6,7)) # return mean of numeric vector
sd(c(3,4,5,6,7)) # returns standard deviation of numeric vector
cor(c(3,4,5,6,7), c(61,47,18,18,5)) # correlation of x and y vectors make sure to set arg use for NAs
range(c(3,4,5,6,7)) # returns min and max as numeric vector of 2
quantile(c(3,4,5,6,7), probs = 0.25) # returns 25th percentile
cos(1)
sin(1)
log(5) # nat log
log2(5) # log base 2
log10(5) # log base 10
exp(5) # exponentiate x
-c(0.5,0.8,10) # distributes the negative to all elements of vector

# vectorized operations
x <- 1:4; y <- 6:9 # different length vectors
x + y # add the elements of the vectors, all operators work
x > 2 # returns logical vector, >= or == or any of the logical expressions work

# Matrix Operations
x <- matrix(1:4,2,2); y <- matrix(rep(10,4),2,2)
x * y # element wise multiplication, for all operators
x %*% y # matrix multiplication

x <- matrix(rnorm(200), 20, 10)
rowSums(x) # vector of sum of rows
rowMeans(x) # vector of mean of rows
colSums(x) # vector of sum of cols
colMeans(x) # vector of mean of cols
x <- matrix(rnorm(100), 10, 10)
solve(x) # returns inverse of matrix if invertible

# Logical operators
5 >= 2 # returns logical. <, >, <=, >=, ==, !=. NA in expression returns NA. Can also use to compare logical vectors themselves.
TRUE | FALSE # OR A|B union, AND A&B intersection, NOT !A negation. & operates across vector, && evaluates first element of vector. Order of operations: AND before OR
isTRUE(6 > 4) # also evaluates logical expression
xor(5 == 6, !FALSE) # only returns TRUE if one is TRUE, one is FALSE
5 %in% c(1,4,6,8) # checks if value is in the vector
c(5,6) %in% c(1,4,6,8) # vectorized, each gives logical
which(c(1,2,3,4,5,6) < 2) # returns indices of logical vector where element is TRUE
any(c(1,2,3,4,5,6) < 2) # returns TRUE if any of the logical index values are TRUE
all(c(1,2,3,4,5,6) < 2) # returns TRUE only if all the elements of vector are TRUE

# Character functions
paste(c("My","name","is"),collapse = " ") # join elements into one element, can join multiple vectors with multiple arguments, adds element-by-element with coersion and recycling
c (c("My","name","is"), "Bob") # add to the vector
as.numeric(gsub(",","",c("4,567","34,234"))) # remove comma from string -> numeric

# Factors functions
x <- factor(c("male","female","female","female","male")) # can include levels argument to set order (baseline is first) otherwise alphabetical
x # prints values in vector and levels
table(x) # prints labels and counts present
unclass(x) # strips class to integer with levels of labels

# Missing Values
# represented as NA (missing, with specified class) or NaN (missing or undefined)
# NaN is NA but NA not always NaN
is.na(c (1,2,NA,5,6,NA, NA,3, NaN)) # output logical vector of length of input
is.nan(c (1,2,NaN,5,6,NA, NaN,3)) # output logical vector of length of input

# Workspace functions
x <- 1 # assigns object to x variable in ws
rm("x") # removes variable x from ws
rm(list=ls()) # removes all variables from ws

# Misc
intersect(c(1,2,5,6,7), c(4,2,6,9,6))

```

### Displaying and Summarizing Data
``` {r display}

# Display Data Functions
x <- data.frame(foo = 1:20, rar = 301:320)
print(x) # print whole object
print(object.size(rnorm(1e5)), units = "Mb") # can format print based on units
head(x) # prints preview of first 6 lines
tail(x) # prints preview of last 6 lines

table(c(1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,4,4,5)) # returns table of counts of vector, arg for useNA="ifany" to count NA vals. Can do 2 din tables for multiple variables to chart relationship
table(c(1,1,1,2,2,2,2,2,2,2,2,2,3,3,3,3,4,4,5) %in% c(3)) # get summary of logical count if 1 is in next
warpbreaks$rep <- rep(1:9, len = 54)
ftable(xtabs(breaks ~., data = warpbreaks)) # display 3D table as single table

summary(c(3,4,5,6,7,3,3,5,7,2,8,3,5,6)) # result summaries of the results of various model fitting functions based on class
quantile(c(3,4,5,6,7,3,3,5,7,2,8,3,5,6)) # gives stats quantile calculations, look at numerical spread. Arg for probs = c(0.5,0.75,0.9)
unique(c(3,4,5,6,7,3,3,5,7,2,8,3,5,6)) # returns only unique elements, duplicates removed

# str function - compactly display internal structure of R object (esp large lists). Diagnostic, alternative to summary()
str(unclass(as.POSIXlt(Sys.time()))) # prints list clearly
str(lm) # list of function arguments
str(rnorm(100,2,4)) # type of vector, length, first 5 elements
str(gl(40,10)) # for factors
str(data.frame(foo = 1:10, rar = 301:310, bee = c("g","v","e","d","d","s","c","t","h","s")))

```


### Attributes of objects
``` {r attributes}
x <- c(0.5,105,10,0.1,2)
class(x) # determine class of object
attributes(x) # function to return or modify attributes of object
identical(x,x) # returns logical for if two objects are identical
length(x) # to specifically get the length of vector
dim(x) # to get dimensions of matrix, data frame (row, column)
object.size(x) # return memory occupied in bytes
as.numeric(0:6) # explicit coercion, works on all atomic classes, if not possible converts to NA and warning

# data frames
x <- data.frame(foo=1:4, bar=c(T,T,F,F))
row.names(x) # get and set row names (attributes). Can also use rownames(x)
colnames(x) # get and set row names
nrow(x) # number of rows
ncol(x) # number of columns
data.matrix(x) # converts data frame to matrix, coercion
dim(x) # (row, column) dimensions of data frame
x$cow <- 4:7 # add column called cow
x <- cbind(x, 4:7) # as above, without name
rowSums(x) # vector of sum of rows
rowMeans(x) # vector of mean of rows
colSums(x) # vector of sum of cols
colMeans(x) # vector of mean of cols

# names attribute
x <- 1:3
names(x) # is null
names(x) <- c("foo","bar","norf") #now not numbered vector but named, print x and names(x) with names
vect <- c(foo = 11, bar = 2, norf = NA) # adds elements with names to vector directly
# also for lists, names vectors not items
m <- matrix(1:4,nrow = 2, ncol = 2)
dimnames(m) <- list(c("a","b"),c("c","d")) # each dimension has a name for matrices, rows names then columns

```

### Indexing, Sorting, and Dealing with NAs
``` {r indexing}

# Subsetting Vector
x <- c("a","b","c","c","d","a", NA)
x[1] # more than one element extracted, returns same class as the original, numeric/logical index
x[1:4] # sequence of num index
x[x>"a"] # logical indexing, returns vector where logical is true
u <- x > "a" # create logical vector
x[u] # same as x[x>"a"]
x[!is.na(x) & x > 0] # returns only positive, non NA values
x[c(-2, -10)] # returns vector with 2nd and 10th elements removed

# Sorting vectors
sort(x)
sort(x, decreasing = TRUE)
sort(x, na.last = TRUE) # retains NA vals at end

# Subset data frame
x <- data.frame(foo = 1:6, bar = c("g","h","i","j","k","l"))
x[,1] # first column
x[,"foo"] # foo column, equivalent to x[,1]
x[1:2,"bar"] # first 2 observations of bar variable
x[(x$foo >= 2 & x$foo < 4),] # all vars where logical is true of observations
x[which(x$bar == "h"), "foo"] # get or set foo in the same row as bar of "h", **to deal with NAs**
x[x$bar %in% c("h","j"),] # subset roes that are as given

# Order data frame
x <- data.frame(foo = sample(1:6), bar = sample(c("g","h","i","j","k","l")))
x[order(x$bar),] # sort data frame by given variable
x$fact <- factor(c(4,4,3,2,3,2))
x[order(x$fact,x$foo),] # order by first then second arg
library(plyr)
arrange(x,bar) # equivalent x[order(x$bar),]
arrange(x,desc(bar)) # decreasing order

# Cross tabs
x <- as.data.frame(UCBAdmissions)
xtabs(Freq ~ Gender + Admit, data = x) # find frequency of admittance based on gender

warpbreaks$rep <- rep(1:9, len = 54)
xtabs(breaks ~., data = warpbreaks) # value displayed is breaks broken down by all other variables in dataset (rep, tension, wool) create 3D table
ftable(xtabs(breaks ~., data = warpbreaks)) # display as single table

# Subset list
x <- list(foo = 1:4, bar = 0.6, baz = "hello")
x[1] # list containing first element
x[[1]] # extract from list/data frame, single element, class can change. Ex, numerical vector returned
x$bar # like [[]] but by name. Ex, return num vector 0.6. Equivalent to x[["bar"]]. Expression x["bar"] returns list of bar. Can use partial matching (x$f = x$foo = x[["f", exact = FALSE]]).
x[c(1,3)] # multiple object extraction from list, returns list
name = "foo"
x[[name]] # must be used if using computed index
x[1][3] # return element in element in object
x[[c(1,3)]]

# Subsetting Matrix
x <- matrix(1:6, 2, 3)
x [1,2] # returns vector len 1, different that x[2,1]. Get matrix using arg drop = FALSE.
x[1,] # get num vector of first row, can also get col x[,2]. drop = FALSE also works


# Info about NAs
x <- c(1,2,NA,4,NA,5)
sum(is.na(x)) # Sum of NA values
any(is.na(x)) # logical for if NA are present

# Removing NA values
bad <- is.na(x) # logical vector indicating presence of NA
x[!bad] # removes NA values

x[!is.na(x)] # simplified returns vector removing NA values

# for two vectors, remove all NAs
x <- c(1,2,NA,4,NA,5)
y <- c("a","b",NA,"d","f",NA)
good <- complete.cases(x,y) # logical vectors where there is no NA in either list
x[good]
y[good]

# for data frames, remove all NAs
x <- read.csv("hw1_data.csv") # for data frames
goodVals <- complete.cases(x) # complete rows in the data frame
x[goodVals,]

rm(list=ls())

```


# Random Numbers
``` {r randomnumbers}
# Random number generation
# Probability distribution functions have 4 functions associated: d- density, r- random number generation, p- cumulative distribution, q- quantile function. Normal, gamma, Poisson, binomial, exponential, chi-squared
set.seed(1) # set sequence of random number generation. set.seed(1); rnorm(5) always results in the same sequence (reproducible).
y <- rnorm(1000) # generate vector of 1000 numbers that are standard normal distribution. Agrs: n, mean = 0, sd = 1.
y <- dnorm(c(0.25,0.5,0.75)) # evaluate Normal probability density, (given mean,sd) at point or vector points. Args: x, mean = 0, sd = 1, log = FALSE.
y <- pnorm(0.5) # evaluate cumulative distribution function for normal distribution. Args: q, mean=0, sd=1, lower.tail=TRUE, log.p=FALSE.
y <- qnorm(0.5) # evaluates quantiles for normal distribution. Args: p, mean=0, sd=1, lower.tail=TRUE, log.p=FALSE.
y <- sample(1:6,3) # random selection of 3 elements from array
ints <- sample(10) # random sample all integers from 1 to 10 without replacement. Permutation
nums <- sample(1:10, replace = TRUE) # with replacement
let <- sample(LETTERS) # sample all letters without replacement
flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3,0.7)) # unfair coin
coin <- rbinom(1,1,0.5) # simulating coin flip
unfairflip <- rbinom(1, size = 100, prob = 0.7) # sum of flips above
flips2 <- rbinom(100,1,0.7) # flips above
y <- rpois(10, 1) # generate random poisson variates with given rate. Args: n (count), rate (mean)
pois_mat <- replicate(100, rpois(5, 10))

# Simulate Linear Model Ex
# y = B(o) + B(1) * x + e
# e ~ N(0,2^2) assume x ~ N(0,1^2), B(0) = 0.5, B(1) = 2.
set.seed(20)
x <- rnorm(100)
e <- rnorm(100,0,2)
y <- 0.5 + 2 * x + e
# can combine different distributions
# Poisson: Y ~ Poisson(mu)
# log(mu) = B(0) + B(1)x
# B(0) = 0.5 and B(1) = 0.3
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3 * x
y <- rpois(100, exp(log.mu))

rm(list=ls())

```


# Control Functions and Loop Functions

### Control Functions
``` {r controlfunctions}
# control execution of program

x = 2
# if,else loops
y <- if(x > 3){ # testing condition
  10
} else if(x > 0 & x <= 3) { # can not have or multiple
  5
} else{ # can not have, at end
  0
}

if(x-5 == 0){
  y <- 0
} else{
  y <- 2
}

# for loops
for(i in 1:10) {# execute loop fixed number of times. Args iterator variable and vector(inc seq) or list
  print(i)
}

x <- c("a","b","c","d")
for(i in 1:4){
  print(x[i])
}
for(i in seq_along(x)){
  print(x[i])
}
for(letter in x){
  print(letter)
}
for(i in 1:4) print(x[i])

x <- matrix(1:6,2,3)
for(i in seq_len(nrow(x))) { # nested, don't use more than 2-3 for readability
  for(j in seq_len(ncol(x))) {
    print(x[i,j])
  }
}

# while loops
count <- 0
while(count < 10){ # loop while condition is true
  print(count)
  count <- count + 1
} # be wary of infinite loops!! when condition cannot be true

z <- 5
while(z >= 3 & z <= 10){
  print(z)
  coin <- rbinom(1,1,0.5)
  
  if (coin == 1) z <- z+1
  else z <- z-1
}

# Repeat loop
x0 <- 0.01; tol <- 1e-3
repeat { # infinite loop
  x1 <- rnorm(1)
  if(abs(x1 - x0) < tol) {
    break # break execution of any loop
  }
  else x0 <- x1
}

# control a loop
for(i in 1:100) {
  if(i <= 20) next # skip next iteration of loop
  else {
    if (i > 50) break # exit for loop
  }
}

# return to exit a function, will end control structure inside function

```

### Loop Functions
``` {r loopfunctions}
# Loop functions - useful for looping in the command line
# Hadley Wickham's Journal of Statistical Software paper titled 'The Split-Apply-Combine Strategy for Data Analysis'.

# lapply - loop over a list and evaluate on each element. args: X (list or coercion), FUN (function or function name), ... (other args). returns list with same names if defined. Passes element to function first argument
x <- list(a = 1:5, b = rnorm(10))
lapply(x, mean) # returns list of 2 numerics
x <- 1:4
lapply(x, runif, min = 0, max = 10) # passes subsequent args to function
x <- list(a = matrix(1:4, 2, 2), b = matrix(1:6, 3, 2))
lapply(x, function(elt) elt[,1]) # define an anonymous function inside lapply

# sapply - same as lapply but simplify, i.e. will make list of 1 element vectors a vector, multiple elements same length returns a matrix, else a list
x <- list(a = 1:5, b = rnorm(10))
lapply(x, mean) # now returns vector length 2
# mean only operates on signle element numeric/logical, so need to use loop

# vapply - pre-specify type of return value, safer and faster. Args: X, FUN, FUN.VALUE (generalized vector as template for return), ..., USE.NAMES = TRUE)
vapply(x, mean, numeric(1)) # same as sapply(x, mean)

# apply - apply function over margins of array (good for summary of matrices or higher level array). Not better than for loop except less code. Args: X as above, MARGIN (integer vector showing margins to retain), FUN as above, ... as above
x <- matrix(rnorm(200), 20, 10)
apply(x, 2, mean) # mean of each column by collapsing 1st dimension, returns num vector length of ncol. MARGIN = 1 gives rows collapse cols.
rowSums(x) # equivalent to apply(x, 1, sum)
rowMeans(x) # equivalent to apply(x, 1, mean)
colSums(x) # apply(x, 2, sum)
colMeans(x) #apply(x, 2, mean)
apply(x, 1, quantile, probs = c(0.25, 0.75)) # runs quantile with 2 agrs for every element in list, returns matrix of 2 rows, nrows rows.
a <- array(rnorm(2 * 2 * 10), c(2, 2, 10)) # array in 3D
apply(a, c(1,2), mean) # collapses only 3rd dimension, returns 2x2 matrix. Equivalent rowMeans(a, dims = 2).

# tapply - apply function over subset of a vector. args: X is vector, INDEX is factor/list factors vector same length as X, FUN, ..., simplify = TRUE
x <- c(rnorm(10), runif(10), rnorm(10,1))
f <- gl(3,10) # factor 3 levels, 10 times each
tapply(x,f,mean)

# mapply - multivariate version of lapply. args: FUN as above, ... (arguments to apply over), MoreArgs (other arguments for FUN), SIMPLIFY (logical for if to simplify). Apply over multiple lists. Like nested loop
list(rep(1,4), rep(2,3), rep(3,2), rep(4,1))
mapply(rep, 1:4, 4:1) # equivalent

noise <- function(n,mean,sd){rnorm(n,mean,sd)}
noise(1:5,1:5,2) # gives vector of 5, same as single num args
mapply(noise,1:5,1:5,2) # applies function for each pair, list of 5 of length i

# split - in conjunction with lapply to split objects into subpieces. Args: x (any object), f (factor), drop (logical if empty factors to be dropped) = FALSE, ...
x <- c(rnorm(10), runif(10), rnorm(10,1))
f <- gl(3,10) # factor 3 levels, 10 times each
split(x,f) # tapply without function, sorts into list based on levels, can then use lapply or sapply.
lapply(split(x,f), mean) # in this case can use tapply
# can do data frames
data <- read.csv("hw1_data.csv")
s <- split(data, data$Month)
sapply(s, function(x) colMeans(x[,c("Ozone","Solar.R","Wind")], na.rm = TRUE)) # data$Month coerced into factor
# Multi-level split
x <- rnorm(10)
f1 <- gl(2,5); f2 <- gl(5,2) # ex. race and gender 2 factors
interaction(f1,f1) # combine each pair, 10 factors
split(x, list(f1,f2)) # interaction called, list returned for combination sort, drop = TRUE to remove unused

rm(list=ls())

```

# Defining Functions
``` {r defFunctions}
# stored in txt or R script, functions are R objects. Can pass functions as arguments for other functions, functions can be nested.

myfunction <- function(){ #create a function
  x <- rnorm(100)
  mean(x)
}
myfunction() #call created function
myfunction # prints source code for function
args(myfunction) # returns arguments for passed function

myaddedfunction <- function(x,y){ #create a function with formal arguments x and y
  x + y + rnorm(100) # implicit return last expression
}
myaddedfunction(5,3)
myaddedfunction(4:10,2)

# function with default argument if left unspecified, for common cases
above <- function(x, n = 10){
  use <- x > n
  x[use]
}
above(1:20) # n is default set to 10
above(1:20, 12) # n set at 12

columnmean <- function(y, removeNA = TRUE) {
  nc <- ncol(y)
  means <- numeric(nc)
  for(i in 1:nc) means[i] <- mean(y[,i], na.rm = removeNA)
  invisible(means) # auto-return blocks auto-print
}

# Lazy Evaluation: R evaluated statements and arguments as they come
f <- function (a,b,c){
  print(a)
  #print(b) # error
}
f(3) # prints a, error for b, no rxn to not having c

# ways to call functions
# positional matching and naming can be mixed. Partial matching also allowed, if not found uses positional match.
# named helps for long arg list where most defaults are maintained or if order is hard to remember.
mydata <- rnorm(100)
sd(mydata) # default to first argument
sd(x = mydata)
sd(x = mydata, na.rm = FALSE)
sd(na.rm = FALSE, x = mydata)
sd(na.rm = FALSE, mydata) # remove argument from list, default works on first unspecified arg

# Variable Arguments
# to extend another function without copying arg list of OG function
simon_says <- function(...){
  paste("Simon says:", ...)
}
# or for generic functions passed to methods
# unpacking an ellipses
mad_libs <- function(...){
  args <- list(...)
  place <- args$place
  adjective <- args$adjective
  noun <- args$noun
  paste("News from", place, "today where", adjective, "students took to the streets in protest of the new", noun, "being installed on campus.")
}
# or when number of args unknown in advance (if at beginning, no positional or partial matching)
args(paste) # operates on unknown sets of character vectors

# function as an argument
some_function <- function(func){
  func(2, 4) # returns result of function with 2,4 arguments
}
some_function(mean) # returns mean of 2,4

# Anonymous function (chaos)
evaluate  <- function(func, dat){
  func(dat)
}
evaluate(function(x){x+1}, 6) # creates a function when calling evaluate to add 1

# create a binary operation
"%mult_add_one%" <- function(left, right){
  left * right + 1
}
4 %mult_add_one% 5

```

### Lexical Scoping
``` {r lexicalscoping}
make.power <- function(n) {
  pow <- function(x) {
    x^n
  }
  pow
}

cube <- make.power(3)
square <- make.power(2)
cube(3)
square(3)

# Scoping - environments
search()# provides list of environments
ls(environment(cube)) # object names in function environment, same for square
get("n",environment(cube)) # values in function environment, changes for square

rm(list=ls())

```

# Cleaning Data
- End of process generate: raw data, tidy data set, code book (metadata) describing each variable and its values in the tidy data set, explicit and exact recipe used to convert raw data to tidy data set and code book.  
- Raw Data: original source of data i.e. no processing, editing, summarizing. Must process for data analysis (merging, sub-setting, transforming, etc.), be mindful of processing standards. Colloquially may be later step i.e. genome seq but must use rawest.  
- Processed(tidy) Data: ready for analysis, steps to reach stage must be recorded. Must: one variable per column, each observation in a separate row, different tables for different types of variables, if multiple tables allow for linking. Useful: top row of variable names which are human readable, save one file per table.   
- Code book: info about variables not contained in data incl. units called *Code book*, info about summary choices, info about experimental study design called *Study design*. Often word/text file.  
- Instruction list: in a computer script where input is raw data and output is tidy data with no parameters to the script. If not possible, provide instructions in steps (incl. parameters, software versions, how to use software).  

### Steps to clean Data
- Look at the data, summarize to find out quirks, missing values, etc.  
- Create new data if applicable: i.e. missingness indicators, cutting up quant variables, applying transformations.  
- Reshape data to the desired format from raw data.  

### Creating new varibales in your data table
``` {r createnewvar}
fileUrl <- "https://hub.arcgis.com/api/v3/datasets/42f8856d647a41b89561e10fb60bc98a_0/downloads/data?format=csv&spatialRefId=3857&where=1%3D1"
if(!dir.exists("./testdir")) {
  dir.create("./testdir")
}
download.file(fileUrl, destfile = "./testdir/restdata.csv", method = "curl")
dateDownloaded <- date()
restdata <- read.csv("./testdir/restdata.csv")

# Variable to subset data
restdata$nearMe <- restdata$nghbrhd %in% c("Roland Park", "Homeland") # create col for logical in restdata
table(restdata$nearMe) # summarize data

# Create binary varibales
restdata$walkingDistance <- ifelse(restdata$zipcode == "21210", TRUE, FALSE) # logical using ifelse command, can do a different data type
table(restdata$walkingDistance, restdata$zipcode == "21210")

# Create categorical variables
restdata$zipcode <- as.numeric(restdata$zipcode)
restdata$zipgroups <- cut(restdata$zipcode, breaks  = quantile(restdata$zipcode, na.rm = TRUE)) # cup up the data table based on the zipcodes with given categories, creates factor variables
table(restdata$zipgroups)

library(Hmisc)
restdata$zipgroups2 <- cut2(restdata$zipcode, g = 4) # same as above
table(restdata$zipgroups2)

# Create factor variables
restdata$zcf <- factor(restdata$zipcode)
restdata$zcf[1:10]
as.numeric(restdata$zcf) # helpful in some models

# Mutate function
library(Hmisc); library(plyr)
restdata2 <- mutate(restdata, zipgroups3 = cut2(zipcode, g = 4)) # create a new data frame with new variables (zipgroups3) as defined added through mutate
table(restdata2$zipgroups3)

rm(list = ls())

```

### Reshaping Data
- <http://vita.had.co.nz/papers/tidy-data.pdf>  
- <http://www.slideshare.net/jeffreybreen/reshaping-data-in-r>  
- <http://www.r-bloggers.com/a-quick-primer-on-split-apply-combine-problems/>  
- Useful functions: acast (multi-dim arrays like dcast), arrange (faster reordering), mutate (add new variables).  
``` {r reshaping}

library(reshape2); library(plyr)
head(mtcars)

# Melt data frames
mtcars$carname <- rownames(mtcars)
carmelt <- melt(mtcars, id = c("carname","gear","cyl"), measure.vars = c("mpg","hp")) # assign id variables to keep from prev data table, measure variables exist 1 per row, make the data table skinny and long, multiple rows per ID, differentiated by measure vars. One col def variable type, 1 col for the value
head(carmelt, n=3)
tail(carmelt, n=3)

# Casting data frames
dcast(carmelt, cyl ~ variable) # reshape data as cylinders (rows) broken down by the variables (cols) summarizing using length
dcast(carmelt, cyl ~ variable,mean) # as above, using mean to summarize

# Summing (apply function to) values
head(InsectSprays)
tapply(InsectSprays$count, InsectSprays$spray, sum) # take sum of values within same spray value (i.e. factor sum)

spIns <- split(InsectSprays$count, InsectSprays$spray) # split insect spray into different vectors in a list based on spray col
sapply(spIns, sum) # as tapply above, sum each vector into names vector format

ddply(InsectSprays,.(spray),sum=sum(count)) # get sum using plyr package, list variables to summarize, command to summarize using sum command as listed (of count col). Returns data col
ddply(InsectSprays,.(spray),sum=ave(count, FUN = sum)) # apply sums then create data frame with sum of each factor in that row. Can use to add to dataset

```

### Managing data frames with dplyr
- Package designed to work with data frame (assumes tidy data, properly formatted and annotated), can use with R implementation or data.table, SQL(DBI package), or other implementations.  
- Developed by Hadley Wickham, optimized and distilled plyr (faster, coded low level in C++). Consistent and consise grammar. 
- Format: first arg is a data frame, subsequent args explain what to do with it. Refer to cols just by name without $ operator. Results in new data frame.  

``` {r dplyr}

library(dplyr)

chicago <- readRDS("chicago.rds")
str(chicago)

# select: return subset of cols of a data frame
head(select(chicago, city:dptp)) # use dplyr to select subset of cols by names
head(select(chicago, -(city:dptp))) # exclude in selection, equivalent to head(chicago[, -(match("city", names(chicago)):match("dptp", names(chicago)))]). Can also do reverse.
head(select(chicago, city, dptp)) # gives only two named cols as specified

# filter: extract subset of rows from data frame based on logical condition
chic.f <- filter(chicago, pm25tmean2 > 30) # logical as second arg, creates logical sequence to subset
head(chic.f, 10)
head(filter(chicago, pm25tmean2 > 30, tmpd > 80)) # multiple logical, can sep using commas for and

# arrange: reorder rows of a data frame whle preserving order of other cols
head(arrange(chicago, date)) # arrange dt based on one variable, ascending, can sort by multiple
chicago <- arrange(chicago, desc(date)) # descending

# rename: rename variables in a data frame
chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp) # renames multiple variables
str(chicago)

# mutate: add new variables/columns or transform existing variables
chicago <- mutate(chicago, pm25detrend = pm25-mean(pm25, na.rm = TRUE)) # add new col based on other col, second arrg is function
head(select(chicago, pm25, pm25detrend))

# group_by: split data frame based on categorical variables
chicago <- mutate(chicago, tempcat = factor(1 * (tmpd > 80), labels = c("cold","hot"))) # create factor variable
hotcold <- group_by(chicago,tempcat) # group by factor variable
head(hotcold)
summarize(hotcold, pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2), no2 = median(no2tmean2)) # generate table of factors as rows to split function values as cols.

chicago <- mutate(chicago, year = as.POSIXlt(date)$year + 1900)
years <- group_by(chicago, year)
summarize(years, pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2), no2 = median(no2tmean2)) # count for group is n(), unique count is n_distinct(x)

# %>%: chain operations
chicago %>% mutate(month = as.POSIXlt(date)$mon + 1) %>% group_by(month) %>% summarize(pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2), no2 = median(no2tmean2)) # as above but using clear chain command, reduce temp variables

# summarize: generate summary statistics of different variables in the data frame, possibly within strata
summarize(chicago, pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2), no2 = median(no2tmean2)) # can summarize data into table format, useful using group_by to summarize in strata of factors

# print: prevents printing lots of data to console
tabular <- as_tibble(chicago) # converts to a tbl_df object, can be done before all dplyr operations
tabular # printing useful in tibble, prints neatly and concisely

# join: merge two data sets using ID of common name, join_all for multiple data frames
df1 <- data.frame(id = sample(1:10), x = rnorm(10))
df2 <- data.frame(id = sample(1:10), y = rnorm(10))
arrange(join(df1,df2),id)

df3 <- data.frame(id = sample(1:10), z = rnorm(10))
join_all(list(df1,df2,df3)) # based on common name

```

### Merge data
- Usually done by matching data sets using IDs, similar to SQL.  
- <http://www.statmethods.net/management/merging.html>  
- <http://en.wikipedia.org/wiki/Join_(SQL)>

``` {r merge}

# Get data
if(!dir.exists("./testdir")) dir.create("./testdir")
fileURL1 <- 
  "https://raw.githubusercontent.com/DataScienceSpecialization/courses/refs/heads/master/03_GettingData/03_05_mergingData/data/reviews.csv"
fileURL2 <- "https://raw.githubusercontent.com/DataScienceSpecialization/courses/refs/heads/master/03_GettingData/03_05_mergingData/data/solutions.csv"
download.file(fileURL1,destfile="./testdir/reviews.csv",method="curl")
download.file(fileURL2,destfile="./testdir/solutions.csv",method="curl")
dateDownloaded <- date()
reviews <- read.csv("./testdir/reviews.csv"); solutions <- read.csv("./testdir/solutions.csv")
head(reviews,2)
head(solutions,2)

# merge: args x,y (dataframes),by,by.x,by.y (cols to merge by), all(include all values even if missing). Defalut to merge same name
testingData <- merge(reviews, solutions, by.x = "solution_id", by.y = "id", all = TRUE)
head(testingData)

mergedData <- merge(reviews, solutions, all = TRUE) # merges with all intersecting data, "id", "start", "stop", "time_left", row for each of reviews and solutions
head(mergedData)

# join in dplyr, faster but less featured. Works best for multiple data sets

```

# Tidy data with tidyr
- By Hadley Wickham. Tidy data is formatted in a standard way that facilitates exploration and analysis and works seamlessly with other tidy data tools. Messy data symptoms: Column headers are values, not variable names; Variables are stored in both rows and columns; A single observational unit is stored in multiple tables; Multiple types of observational units are stored in the same table; Multiple variables are stored in one column.  
- <http://vita.had.co.nz/papers/tidy-data.pdf>  

``` {r tidyr}

library(tidyr); library(dplyr); library(readr)

# gather: column headers that are values, not variable names
students <- data.frame(grade = c("A","B","C","D","E"), male = c(1,5,5,5,7), female = c(5,0,2,5,4))
# note the actual variables are grade, sex, and count
gather(students, sex, count, -grade) # now is tidy data, each row is separate observation (grade, sex combo). sex is the key and count is the value (become col names), negative is to gather all except grades(already tidy)

# separate: multiple variables are stored in one column
students2 <- data.frame(grade = c("A","B","C","D","E"), male_1 = c(3,6,7,4,1), female_1 = c(4,4,4,0,1), male_2 = c(3,3,3,8,2), female_2 = c(4,5,8,1,7)) # variables: grade, sex, class, count
res <- gather(students2, sex_class, count, -grade) # split variables of count
separate(res, col = sex_class, into = c("sex","class")) # separate sex_count in same col, splits on non-alphanumeric values (i.e. _) unless specified by sep. Use %>% for tidy code

# spread: variables are stored in both rows and columns
students3 <- data.frame(name = c("Sally","Sally","Jeff","Jeff","Roger","Roger","Bree","Bree","Brian","Brian"), test = rep(c("midterm","final"),5), class1 = c("A","C",NA,NA,NA,NA,NA,NA,"B","B"), class2 = c(NA,NA,"D","E","C","A",NA,NA,NA,NA), class3 = c("B","C",NA,NA,NA,NA,"C","C",NA,NA), class4 = c(NA,NA,"A","C",NA,NA,"A","A",NA,NA), class5 = c(NA,NA,NA,NA,"B","A",NA,NA,"A","C"))
students3 %>%
  gather(key = class, value = grade, class1:class5 , na.rm = TRUE) %>%
  spread(key = test , value = grade) %>%
  mutate(class = parse_number(class)) %>%
  print

# Multiple observational units stored in same table
students4 <- data.frame(id = c(168,168,588,588,710,710,731,731,908,908), name = c("Sally","Sally","Jeff","Jeff","Roger","Roger","Bree","Bree","Brian","Brian"), sex = c("F","F","M","M","M","M","F","F","M","M"), class = c(1,5,1,3,2,4,2,5,3,4), midterm = c("B","A","A","B","D","A","C","B","C","A"), final = c("B","C","C","C","E","C","A","A","C","A"))
student_info <- students4 %>%
  select(id, name, sex) %>%
  unique %>%
  print
gradebook <- students4 %>%
  select(id, class, midterm, final) %>%
  print

# single observational unit is stored in multiple tables
passed <- data.frame(name = c("Brian","Roger","Roger","Karen"), class = c(1,2,5,4), final = c("B","A","A","A"))
failed <- data.frame(name = c("Brian","Sally","Sally","Jeff","Jeff","Karen"), class = c(5,1,3,2,4,3), final = c("C","C","C","E","C","C"))
failed <- mutate(failed, status = "failed")
passed <- mutate(passed, status = "passed")
bind_rows(passed, failed)

rm(list=ls())

```
